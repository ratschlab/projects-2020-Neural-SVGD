{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "from jax import config\n",
    "config.update(\"jax_debug_nans\", False)\n",
    "# config.update(\"jax_disable_jit\", True)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../../../learning_particle_gradients/\")\n",
    "import json_tricks as json\n",
    "import copy\n",
    "from functools import partial\n",
    "\n",
    "from tqdm import tqdm\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, random, lax, jacfwd, value_and_grad\n",
    "from jax import lax\n",
    "from jax.ops import index_update, index\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as onp\n",
    "import jax\n",
    "import pandas as pd\n",
    "import haiku as hk\n",
    "from jax.experimental import optimizers\n",
    "\n",
    "\n",
    "import utils\n",
    "import metrics\n",
    "import time\n",
    "import plot\n",
    "import stein\n",
    "import kernels\n",
    "import distributions\n",
    "import nets\n",
    "import models\n",
    "import flows\n",
    "\n",
    "from jax.experimental import optimizers\n",
    "\n",
    "key = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up exporting\n",
    "import matplotlib\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "#     'font.family': 'serif',\n",
    "#     'text.usetex': False,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "figure_path = \"/home/lauro/documents/msc-thesis/thesis/figures/\"\n",
    "# save figures by using plt.savefig('title of figure')\n",
    "# remember that latex textwidth is 5.4in\n",
    "# so use figsize=[5.4, 4], for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetEmbedding(hk.Module):\n",
    "    def __init__(self, phi_sizes, w_init=hk.initializers.VarianceScaling(2.0), name=None):\n",
    "        \"\"\"embed_size: integer, output dimension\"\"\"\n",
    "        super().__init__(name=name)\n",
    "        self.sizes = phi_sizes\n",
    "        self.w_init = w_init\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"x is a set of shape (n, ...), where n\n",
    "        is the number of element in the set.\n",
    "\n",
    "        Computes:\n",
    "        x1, ..., xn --> phi(x1), ..., phi(xn) --> mean(...)\n",
    "        \"\"\"\n",
    "        n = x.shape[0]\n",
    "        phi = hk.nets.MLP(output_sizes=self.sizes,\n",
    "                          w_init=self.w_init,\n",
    "                          activation=jax.nn.swish,\n",
    "                          activate_final=True)\n",
    "\n",
    "        set_embedding = hk.Sequential([\n",
    "            phi,\n",
    "            partial(np.mean, axis=0),\n",
    "        ])\n",
    "        return set_embedding(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32\n",
    "hidden_state_size = 2\n",
    "\n",
    "def embed_fn(x):\n",
    "    \"\"\"x is an array of shape (n, d)\"\"\"\n",
    "    e = SetEmbedding([32, 32])(x)\n",
    "    return hk.nets.MLP([32, embedding_dim])(e)\n",
    "\n",
    "# embed = hk.transform(embed_fn)\n",
    "\n",
    "\n",
    "def cell_fn(particles, state):\n",
    "    \"\"\"\n",
    "    particles: particles (input) of shape (n, d)\n",
    "    state: particle (hidden state) of shape (d,)\"\"\"\n",
    "    cell = hk.GRU(hidden_state_size)\n",
    "    return cell(embed_fn(particles), state)\n",
    "\n",
    "cell = hk.transform(cell_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get RNN to update particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = distributions.Gaussian([0, 0], [1,1])\n",
    "proposal = distributions.Gaussian([-2, 0], [1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "key, subkey = random.split(key)\n",
    "init_particles = proposal.sample(100)\n",
    "x = init_particles[0]\n",
    "\n",
    "print(init_particles.shape)\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "params = cell.init(subkey, init_particles, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([-1.0212189,  0.7661866], dtype=float32),\n",
       " DeviceArray([-1.0212189,  0.7661866], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single update\n",
    "key, subkey = random.split(key)\n",
    "cell.apply(params, subkey, init_particles, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = init_particles\n",
    "particles, _ = cell.apply(params, subkey, particles, particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_loss(params, subkey, particles):\n",
    "    def delta(x):\n",
    "        xnew, _ = cell.apply(params, subkey, particles, x)\n",
    "        return xnew - x\n",
    "\n",
    "    sd = stein.stein_discrepancy(particles, target.logpdf, delta)\n",
    "    return -sd + utils.l2_norm_squared(particles, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.39911443, dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_loss(params, subkey, particles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-cell loss: propagate particles through $m$ unrolled cells, and average losses from all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_cell_loss(params, subkey, particles, unroll_length):\n",
    "    for i in range(unroll_length):\n",
    "        ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-thesis",
   "language": "python",
   "name": "msc-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
