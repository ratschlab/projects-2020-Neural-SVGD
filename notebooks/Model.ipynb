{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauro/.virtualenvs/msc-thesis/lib/python3.8/site-packages/jax/lib/xla_bridge.py:125: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/home/lauro/code/msc-thesis/svgd\")\n",
    "enable_float64 = True\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", enable_float64)\n",
    "# config.update(\"jax_debug_nans\", True)\n",
    "import json_tricks as json\n",
    "import copy\n",
    "\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, random, lax, jacfwd\n",
    "from jax import lax\n",
    "from jax.ops import index_update, index\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as onp\n",
    "import jax\n",
    "import pandas as pd\n",
    "import haiku as hk\n",
    "\n",
    "import config\n",
    "\n",
    "import utils\n",
    "import metrics\n",
    "import time\n",
    "import plot\n",
    "import stein\n",
    "import kernels\n",
    "from svgd import SVGD\n",
    "\n",
    "from jax.experimental import optimizers\n",
    "\n",
    "key = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rundata(true, *args, labels=None, ax=None, title=None):\n",
    "    ax = plt.gca() if ax is None else ax\n",
    "    colorcycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    styles = [\"-\", \"--\", \"-.\", \":\"]\n",
    "    for data, label, style in zip(args, labels, styles):\n",
    "        ax.set_prop_cycle(color=colorcycle)\n",
    "        ax.plot(data, style, label=label)\n",
    "        length = len(data)\n",
    "\n",
    "    # True parameters\n",
    "    _ = ax.hlines(true, 0, length, colors=colorcycle, linestyles=\"dotted\")\n",
    "    ax.legend()\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla ARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = copy.deepcopy(config.config)\n",
    "# conf[\"svgd\"][\"target_args\"] = [[0, 5], [1, 3]]\n",
    "conf[\"svgd\"][\"target\"] = \"Gaussian Mixture\"\n",
    "conf[\"svgd\"][\"target_args\"] = metrics.bent_args\n",
    "\n",
    "conf[\"svgd\"][\"n_particles\"] = 6000\n",
    "conf[\"svgd\"][\"n_subsamples\"] = 100\n",
    "\n",
    "conf[\"train_kernel\"][\"train\"] = False\n",
    "conf[\"train_kernel\"][\"svgd_steps\"] = 1\n",
    "conf[\"train_kernel\"][\"n_iter\"] = 80 #config.config[\"train_kernel\"][\"n_iter\"] // conf_mlp[\"train_kernel\"][\"svgd_steps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/80 [00:40<03:14,  2.90s/it]"
     ]
    }
   ],
   "source": [
    "svgd_vanilla = SVGD(**config.get_svgd_args(conf))\n",
    "key, subkey = random.split(key)\n",
    "rundata_vanilla = svgd_vanilla.sample(subkey, **config.get_sample_args(conf))\n",
    "\n",
    "t_mean = onp.array(rundata_vanilla[\"leader_mean\"])\n",
    "t_var = onp.array(rundata_vanilla[\"leader_var\"])\n",
    "v_mean = onp.array(rundata_vanilla[\"validation_mean\"])\n",
    "v_var = onp.array(rundata_vanilla[\"validation_var\"])\n",
    "tru_mean = svgd_mlp.target.mean\n",
    "tru_var = onp.diag(svgd_mlp.target.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=[22, 4])\n",
    "plot_rundata(tru_mean, t_mean, v_mean, labels=[\"Leader Mean\", \"Validation Mean\"], ax=axs[0])\n",
    "plot_rundata(tru_var, t_var, v_var, labels=[\"Leader Variance\", \"Validation Variance\"], ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[11, 4])\n",
    "ax.plot(rundata_vanilla[\"ksd_after_svgd_update\"])\n",
    "ax.plot(rundata_vanilla[\"ksd_after_svgd_update_val\"])\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rundata_vanilla[\"mean_drift\"], label=\"Mean Drift\")\n",
    "plt.plot(rundata_vanilla[\"mean_repulsion\"], label=\"Mean Repulsion\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.bivariate_hist(rundata_vanilla[\"particles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot errorbars cts\n",
    "\n",
    "# t_mean = onp.array(rundata_vanilla[\"training_mean\"])\n",
    "# t_var = onp.array(rundata_vanilla[\"training_var\"])\n",
    "# v_mean = onp.array(rundata_vanilla[\"validation_mean\"])\n",
    "# v_var = onp.array(rundata_vanilla[\"validation_var\"])\n",
    "# tru_mean = conf[\"svgd\"][\"target_args\"][0]\n",
    "# tru_var = conf[\"svgd\"][\"target_args\"][1]# if conf_mlp[\"svgd\"][\"target_args\"][1].shape == (2,2) else diag(conf_mlp[\"svgd\"][\"target_args\"][1])\n",
    "# grid = np.arange(len(t_mean))\n",
    "\n",
    "# # fig, ax = plt.subplots(1,2, figsize=[14, 4])\n",
    "\n",
    "# def plot_mean_and_var(mean, var, tru_mean, tru_var, ax=None):\n",
    "#     colorcycle = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "#     ax = ax if ax is not None else plt.gca()\n",
    "#     for i in range(2):\n",
    "#         plot.errorfill(grid, mean[:, i], np.sqrt(var[:, i]), color=next(colorcycle), ax=ax)\n",
    "#         ax.errorbar(len(t_mean), tru_mean[i], np.sqrt(tru_var[i]), marker=\"o\", capsize=5)\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=[14, 4])\n",
    "# for m, v, ax, title in zip((t_mean, v_mean), (t_var, v_var), axs, (\"Training\", \"Validation\")):\n",
    "#     plot_mean_and_var(m, v, tru_mean, tru_var, ax)\n",
    "#     ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mlp = copy.deepcopy(config.config)\n",
    "\n",
    "# conf_mlp[\"svgd\"][\"target_args\"] = [[0, 5], [1, 3]]\n",
    "conf_mlp[\"svgd\"][\"target\"] = \"Gaussian Mixture\"\n",
    "conf_mlp[\"svgd\"][\"target_args\"] = metrics.bent_args\n",
    "\n",
    "conf_mlp[\"svgd\"][\"n_particles\"] = 6000\n",
    "conf_mlp[\"svgd\"][\"n_subsamples\"] = 100\n",
    "conf_mlp[\"svgd\"][\"lam\"] = 1\n",
    "conf_mlp[\"svgd\"][\"encoder_layers\"] = [8, 8, 8, 2]\n",
    "conf_mlp[\"svgd\"][\"decoder_layers\"] = [8, 8, 4, 1]\n",
    "\n",
    "conf_mlp[\"train_kernel\"][\"ksd_steps\"] = 5\n",
    "conf_mlp[\"train_kernel\"][\"svgd_steps\"] = 1\n",
    "conf_mlp[\"train_kernel\"][\"n_iter\"] = 80 #config.config[\"train_kernel\"][\"n_iter\"] // conf_mlp[\"train_kernel\"][\"svgd_steps\"]\n",
    "conf_mlp[\"train_kernel\"][\"optimizer_ksd_args\"] = [0.03]\n",
    "conf_mlp[\"train_kernel\"][\"lamda_reg\"] = 1e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svgd_mlp = SVGD(**config.get_svgd_args(conf_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = config.get_train_args(conf_mlp)\n",
    "key, subkey = random.split(key)\n",
    "encoder_params_mlp, rundata_mlp = svgd_mlp.train_kernel(key, **train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onp.diag(svgd_mlp.target.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mean = onp.array(rundata_mlp[\"training_mean\"])\n",
    "v_mean = onp.array(rundata_mlp[\"validation_mean\"])\n",
    "l_mean = onp.array(rundata_mlp[\"leader_mean\"])\n",
    "\n",
    "v_var = onp.array(rundata_mlp[\"validation_var\"])\n",
    "t_var = onp.array(rundata_mlp[\"training_var\"])\n",
    "l_var = onp.array(rundata_mlp[\"leader_var\"])\n",
    "\n",
    "tru_mean = svgd_mlp.target.mean\n",
    "tru_var = onp.diag(svgd_mlp.target.cov)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=[22, 4])\n",
    "plot_rundata(tru_mean, l_mean, t_mean, v_mean, labels=[c + \" Mean\" for c in (\"Leader\", \"Training\", \"Validation\")], ax=axs[0])\n",
    "plot_rundata(tru_var, l_var, t_var, v_var, labels=[c + \" Variance\" for c in (\"Leader\", \"Training\", \"Validation\")], ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[10, 5])\n",
    "ax.plot(rundata_mlp[\"ksd_before_kernel_update\"], \".\", label=\"Training KSD\")\n",
    "ax.plot(rundata_mlp[\"ksd_before_kernel_update_val\"], \".\", label=\"Validation KSD\")\n",
    "# ax.plot(rundata_mlp[\"ksd_after_svgd_update\"], \".\", label=\"KSD after SVGD step\")\n",
    "ax.set_yscale(\"log\")\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[10, 5])\n",
    "section = list(range(0, 200))\n",
    "ax.plot(section, rundata_mlp[\"autoencoder_loss\"][section] * train_args[\"lambda_reg\"], label=\"autoencoder loss\")\n",
    "# ax.plot(section, rundata_mlp[\"regularized_loss\"][section], label=\"Total loss = autoencoder - KSD\")\n",
    "ax.plot(section, rundata_mlp[\"ksd_before_kernel_update\"][section], label=\"KSD\")\n",
    "ax.legend()\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rundata_mlp[\"mean_drift\"], label=\"Mean Drift\")\n",
    "plt.plot(rundata_mlp[\"mean_repulsion\"], label=\"Mean Repulsion\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.bivariate_hist(rundata_mlp[\"particles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rundata_mlp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rundata_mlp[\"is_pd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update-to-weight-ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_update_to_weight_ratio(update_to_weight_ratio, scale=\"log\"):\n",
    "    con = update_to_weight_ratio\n",
    "    def visit(d, prefix=\"\"):\n",
    "        for k, v in d.items():\n",
    "            if type(v) is jax.interpreters.xla.DeviceArray or type(v) is onp.ndarray or type(v) is list:\n",
    "                plt.plot(v, label=prefix+\"//\"+k)\n",
    "            else:\n",
    "                visit(v, k)\n",
    "    visit(con)\n",
    "    plt.yscale(scale)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_update_to_weight_ratio(rundata_mlp[\"update_to_weight_ratio\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoded / decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc(x): return svgd_mlp.encoder.apply(encoder_params_mlp, None, x)\n",
    "def dec(x): return svgd_mlp.decoder.apply(rundata_mlp[\"decoder_params\"], None, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = svgd_mlp.target.sample(1000)\n",
    "out = vmap(enc)(sample)\n",
    "recoded = vmap(dec)(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.bivariate_hist(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.bivariate_hist(recoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.bivariate_hist(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(out[:, 1], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_iter = conf_mlp[\"train_kernel\"][\"n_iter\"]\n",
    "# # ksd_kernel = np.split(rundata_mlp[\"ksd_after_kernel_update\"], n_iter)\n",
    "# # ksd_svgd = np.split(rundata_mlp[\"ksd_after_svgd_update\"], n_iter)\n",
    "# ksd_kernel = rundata_mlp[\"ksd_after_kernel_update\"]\n",
    "\n",
    "#     ax.plot(ksdss)\n",
    "\n",
    "\n",
    "# for i, ksds in enumerate(ksd_kernel):\n",
    "#     idx = range(40*i, 40*i+20)\n",
    "# #     print(\"k range:\", idx)\n",
    "#     ax.plot(idx, ksds, \".b\")\n",
    "\n",
    "# for i, ksds in enumerate(ksd_svgd):\n",
    "#     start = 40*(i+1) - 20\n",
    "#     stop = 40*(i+1)\n",
    "#     step = 5\n",
    "#     idx = range(start, stop, step)\n",
    "# #     print(\"s range:\", idx)\n",
    "#     ax.plot(idx, ksds, \".r\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-thesis",
   "language": "python",
   "name": "msc-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
