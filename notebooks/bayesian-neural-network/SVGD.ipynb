{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a BNN to classify MNIST using SVGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "# for leonhard\n",
    "import os\n",
    "try:\n",
    "    os.environ['XLA_FLAGS'] = \"--xla_gpu_cuda_data_dir=\" + os.environ[\"CUDA_HOME\"]\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "# Train a Bayesian neural network to classify MNIST using\n",
    "# Neural SVGD\n",
    "#\n",
    "# If using pmap, set the environment variable\n",
    "# `export XLA_FLAGS=\"--xla_force_host_platform_device_count=8\"`\n",
    "# before running on CPU (this enables pmap to \"see\" multiple cores).\n",
    "import sys\n",
    "import os\n",
    "on_cluster = not os.getenv(\"HOME\") == \"/home/lauro\"\n",
    "if on_cluster:\n",
    "    sys.path.append(\"/cluster/home/dlauro/projects-2020-Neural-SVGD/learning_particle_gradients/\")\n",
    "sys.path.append(\"../../experiments/\")\n",
    "\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import vmap, random\n",
    "import jax.numpy as jnp\n",
    "import numpy as onp\n",
    "from tqdm import tqdm\n",
    "import optax\n",
    "import bnn\n",
    "import models\n",
    "import metrics\n",
    "import mnist\n",
    "import config as cfg\n",
    "import utils\n",
    "from jax import jit, grad, value_and_grad\n",
    "\n",
    "# Config\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "NUM_SAMPLES = 100\n",
    "DISABLE_PROGRESS_BAR = False\n",
    "USE_PMAP = False\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "LAMBDA_REG = 1/2\n",
    "STEP_SIZE = 1e-5\n",
    "PATIENCE = 15\n",
    "MAX_TRAIN_STEPS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init particles and dynamics model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svgd_bnn import train as train_svgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = [1e-6, 5e-6, 8e-6, 1e-5, 2e-5, 5e-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = random.split(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Starting epoch 1\n"
     ]
    }
   ],
   "source": [
    "for particle_stepsize in tqdm(lrs):\n",
    "    final_acc = train_svgd(key=subkey,\n",
    "                               particle_stepsize=particle_stepsize,\n",
    "                               n_iter=200,\n",
    "                               evaluate_every=-1,\n",
    "                               results_file=\"/dev/null\",\n",
    "                               optimizer=\"sgd\")\n",
    "    final_accs.append((final_acc, particle_stepsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = onp.array(final_accs)\n",
    "fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE = fa[fa[:, 0].argmax(), 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_particles_fn(subkey):\n",
    "    init_particles = vmap(bnn.init_flat_params)(random.split(subkey, NUM_SAMPLES))\n",
    "    return init_particles\n",
    "\n",
    "\n",
    "key, subkey = random.split(key)\n",
    "init_particles = init_particles_fn(subkey)\n",
    "opt = optax.sgd(STEP_SIZE)\n",
    "\n",
    "key, subkey1, subkey2 = random.split(key, 3)\n",
    "svgd_grad = models.KernelGradient(get_target_logp=bnn.get_minibatch_logp,\n",
    "                                  scaled=False)\n",
    "\n",
    "particles = models.Particles(key=subkey2,\n",
    "                             gradient=svgd_grad.gradient,\n",
    "                             init_samples=init_particles,\n",
    "                             custom_optimizer=opt)\n",
    "\n",
    "# minibatch_vdlogp = jit(vmap(value_and_grad(bnn.minibatch_logp), (0, None)))\n",
    "\n",
    "@jit\n",
    "def compute_eval(step_counter, ps, loglikelihood):\n",
    "    stepdata = {\n",
    "        \"accuracy\": (step_counter, bnn.compute_acc_from_flat(ps)),\n",
    "        \"particle_mean\": (step_counter, ps.mean()),\n",
    "        \"loglikelihood\": loglikelihood.mean(),\n",
    "    }\n",
    "    return stepdata\n",
    "\n",
    "\n",
    "SGLD_STEPSIZE = 5e-8\n",
    "print('SGLD noise   :', jnp.sqrt(2*SGLD_STEPSIZE))\n",
    "print('NVGD stepsize:', STEP_SIZE)\n",
    "sgld = utils.sgld(SGLD_STEPSIZE)\n",
    "sgld_state = sgld.init(init_particles)\n",
    "\n",
    "\n",
    "@jit\n",
    "def sgld_step(particles, dlogp, sgld_state):\n",
    "    \"\"\"Update param_set elements in parallel using Langevin dynamics.\"\"\"\n",
    "    g, sgld_state = sgld.update(-dlogp, sgld_state, particles)\n",
    "    particles = optax.apply_updates(particles, g)\n",
    "    aux = {\n",
    "        \"global_grad_norm\": optax.global_norm(g),\n",
    "    }\n",
    "    return particles, sgld_state, aux\n",
    "\n",
    "step_counter = 0\n",
    "\n",
    "# num_steps = EPOCHS * data_size // BATCH_SIZE // 5\n",
    "num_steps = 200\n",
    "sgld_aux = {}\n",
    "for _ in tqdm(range(num_steps)):\n",
    "    step_counter += 1\n",
    "    train_batch = next(mnist.training_batches)\n",
    "    particles.step(train_batch)\n",
    "\n",
    "    if step_counter % 10 == 0:\n",
    "        metrics.append_to_log(particles.rundata,\n",
    "                              compute_eval(step_counter,\n",
    "                                           particles.particles,\n",
    "                                           jnp.array(1)))\n",
    "        \n",
    "# neural_grad.done()\n",
    "# particles.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 5])\n",
    "ax.plot(*zip(*particles.rundata['accuracy']), \"--.\", label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles.rundata['accuracy'][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles.rundata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = onp.array(particles.rundata['particles'])\n",
    "trajectories.shape\n",
    "\n",
    "# visualize trajectory avg across dimensions (distinguish particles)\n",
    "fig, axs = plt.subplots(2, 1, figsize=[10, 8])\n",
    "\n",
    "ax = axs[0]\n",
    "ax.plot(trajectories.mean(axis=2));  # avg across dims\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(trajectories[:, :, 1]);  # watch single param (aka single dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
