{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "jit() missing 1 required positional argument: 'fun'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d583bc06b5e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/msc-thesis/svgd/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvgd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/msc-thesis/svgd/metrics.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0monp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msvgd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstein\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/msc-thesis/svgd/svgd.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstein\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/msc-thesis/svgd/stein.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mksd_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic_argnums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mksd_squared_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_variance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \"\"\"\n",
      "\u001b[0;31mTypeError\u001b[0m: jit() missing 1 required positional argument: 'fun'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"/home/lauro/code/msc-thesis/svgd\")\n",
    "import json\n",
    "import collections\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "import numpy as onp\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, random, lax, jacfwd, value_and_grad, lax\n",
    "from jax.scipy import stats\n",
    "from jax.ops import index_update, index\n",
    "from jax.experimental import optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as onp\n",
    "import jax\n",
    "import pandas as pd\n",
    "import haiku as hk\n",
    "import ot\n",
    "from tqdm import tqdm\n",
    "\n",
    "import config\n",
    "\n",
    "import utils\n",
    "import metrics\n",
    "import time\n",
    "import plot\n",
    "import svgd\n",
    "import stein\n",
    "import kernels\n",
    "\n",
    "from jax.experimental import optimizers\n",
    "\n",
    "rkey = random.PRNGKey(0)\n",
    "key, rkey = random.split(rkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = metrics.Funnel(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = f.sample(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: see if MLP can learn optimal encoding for funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_funnel(z):\n",
    "    \"\"\"encode single sample z, shaped (d,)\"\"\"\n",
    "    *x, y = z\n",
    "    x, y = np.asarray(x), np.asarray(y)\n",
    "    x_enc = x * np.exp(-y/2)\n",
    "    return np.append(x_enc, y)\n",
    "\n",
    "def dec_funnel(z):\n",
    "    \"\"\"decode single sample z, shaped (d,)\"\"\"\n",
    "    *x, y = z\n",
    "    x, y = np.asarray(x), np.asarray(y)\n",
    "    x_dec = x * np.exp(y/2)\n",
    "    return np.append(x_dec, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random.normal(key, (10000, 2))\n",
    "x = x * np.array([1, 3])\n",
    "z = vmap(dec_funnel)(x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[5,5])\n",
    "ax.scatter(z[:, 0], z[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learn encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funnel = metrics.Funnel(2)\n",
    "encoder = hk.transform(kernels.make_mlp([8, 8, 8, 8, 2], name=\"encoder\", skip_connection=True))\n",
    "def loss(encoder_params, x):\n",
    "    return np.linalg.norm(encoder.apply(encoder_params, None, x) - enc_funnel(x))**2\n",
    "@jit\n",
    "def loss_batched(encoder_params, x):\n",
    "    return np.mean(vmap(loss, (None, 0))(encoder_params, x))\n",
    "\n",
    "key, subkey = random.split(key)\n",
    "x_dummy = np.asarray([1., 1.])\n",
    "init_params = encoder.init(subkey, x_dummy)\n",
    "opt = svgd.Optimizer(*optimizers.adam(0.01))\n",
    "opt_state = opt.init(init_params)\n",
    "\n",
    "nsteps=1000\n",
    "losses=[]\n",
    "for step in tqdm(range(nsteps)):\n",
    "    x = funnel.sample(500)\n",
    "    encoder_params = opt.get_params(opt_state)\n",
    "    l, g = value_and_grad(loss_batched, argnums=0)(encoder_params, x)\n",
    "    opt_state = opt.update(step, g, opt_state)\n",
    "    losses.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## see if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_mlp(z): return encoder.apply(encoder_params, None, z)\n",
    "\n",
    "z = f.sample(1000)\n",
    "encoded = vmap(enc_funnel)(z)\n",
    "mlp_encoded = vmap(enc_mlp)(z)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[5,6])\n",
    "# ax=axs[0]\n",
    "ax.scatter(encoded[:, 0], encoded[:, 1], marker=\".\", label=\"Fixed encoded\")\n",
    "# ax=axs[0]\n",
    "ax.scatter(mlp_encoded[:, 0], mlp_encoded[:, 1], marker=\".\", label=\"Learned encoding\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does the encoded kernel have larger ksd than the rbf kernel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "* make sure we're using a near-maximal bandwidth for the KSD to the standard normal\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5000\n",
    "key, s1, s2 = random.split(key, 3)\n",
    "# x = random.normal(s1, (n, 2))    # P = N(0_2, I)\n",
    "y = random.normal(s2, (n, 2)) -2 # Q = N([-2,-2], I)\n",
    "\n",
    "def t(v):\n",
    "    \"\"\"if v~N(0_2, I_2), then output w~Funnel(2)\"\"\"\n",
    "    *x, y = v\n",
    "    x, y = np.asarray(x), np.asarray(y)\n",
    "    y = y*3\n",
    "    x = x*np.exp(y/2)\n",
    "    return np.append(x, y)\n",
    "# tx = vmap(t)(x) # T(X) ~ Funnel(2)\n",
    "ty = vmap(t)(y) # T(Y)\n",
    "\n",
    "qloc = np.asarray([-2, -2])\n",
    "ploc = np.asarray([0, 0])\n",
    "qscale = onp.diag([1, 1])\n",
    "pscale = onp.diag([1, 1])\n",
    "def logp(x): return stats.multivariate_normal.logpdf(x, mean=ploc, cov=pscale)\n",
    "\n",
    "# get both kernel functions\n",
    "rbf = kernels.ard(logh=-5)\n",
    "def rbf_enc(x, y): return rbf(enc_funnel(x), enc_funnel(y))\n",
    "\n",
    "print(\"P ~ N(0, I_2)\")\n",
    "print(\"Q ~ N(-2, I_2)\")\n",
    "print(\"T_#P is dist of T(X) when X~P. That is, F = Neal's Funnel\")\n",
    "print(\"T_#Q is dist of T(Y) when Y~Q\")\n",
    "print(\"--------------\")\n",
    "print(\"Now estimate the KSD.\")\n",
    "# print(\"# V-statistics:\")\n",
    "# print(\"KSD(Q, P      ;rbf)     =\", stein.ksd_squared_u(y, logp, rbf)) # not equal to below\n",
    "# print(\"KSD(T_#Q, T_#P; T_#rbf) =\", stein.ksd_squared_v(ty, funnel.logpdf, rbf_enc))\n",
    "# print(\"KSD(T_#Q, T_#P; rbf)    =\", stein.ksd_squared_v(ty, funnel.logpdf, rbf))\n",
    "\n",
    "print(\"# U-statistics:\")\n",
    "print(\"KSD(T_#Q, T_#P; T_#rbf) =\", stein.ksd_squared_u(ty, funnel.logpdf, rbf_enc, False), \"(Would like this to be bigger)\")\n",
    "print(\"KSD(T_#Q, T_#P; rbf)    =\", stein.ksd_squared_u(ty, funnel.logpdf, rbf, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot.scatter(ty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### same thing with different proposal Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data should be near the funnel distribution, but not quite right\n",
    "# (e.g. to wide at the narrow part of the funnel)\n",
    "zo = funnel.sample(5000)\n",
    "def mess_up_funnel(zo):\n",
    "    z = copy.copy(onp.asarray(zo))\n",
    "    z[z[:, 0]>0, 0] = np.sqrt(z[z[:, 0]>0, 0])\n",
    "    z[z[:, 0]<0, 0] = -np.sqrt(-z[z[:, 0]<0, 0])\n",
    "    return z\n",
    "z = mess_up_funnel(zo)\n",
    "\n",
    "# compute ksd\n",
    "print(\"KSD(Z, F; rbf)    =\", stein.ksd_squared_u(z, funnel.logpdf, rbf))\n",
    "print(\"KSD(Z, F; T_#rbf) =\", stein.ksd_squared_u(z, funnel.logpdf, rbf_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.scatter(z, marker=\".\")\n",
    "plt.ylim((-9,9))\n",
    "plt.xlim((-20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check nr 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens when we maximize the KSD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# plot.plot_pdf(f.pdf, (-20, 20), type=\"3d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-thesis",
   "language": "python",
   "name": "msc-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
