{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauro/.virtualenvs/msc-thesis/lib/python3.8/site-packages/jax/lib/xla_bridge.py:125: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import copy\n",
    "import os\n",
    "sys.path.append(\"/home/lauro/code/msc-thesis/svgd/kernel_learning\")\n",
    "import json\n",
    "import collections\n",
    "import itertools\n",
    "from functools import partial\n",
    "import importlib\n",
    "\n",
    "import numpy as onp\n",
    "from jax.config import config\n",
    "# config.update(\"jax_log_compiles\", True)\n",
    "# config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, random, lax, jacfwd, value_and_grad\n",
    "from jax import lax\n",
    "from jax.ops import index_update, index\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as onp\n",
    "import jax\n",
    "import pandas as pd\n",
    "import haiku as hk\n",
    "import ot\n",
    "\n",
    "import config\n",
    "\n",
    "import utils\n",
    "import metrics\n",
    "import time\n",
    "import plot\n",
    "from svgd import SVGD, Optimizer\n",
    "import stein\n",
    "import kernels\n",
    "import distributions\n",
    "import nets\n",
    "import kernel_learning\n",
    "\n",
    "from jax.experimental import optimizers\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "from jax.scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funnel kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = distributions.Funnel(2)\n",
    "proposal = distributions.Uniform([[-1, 1], [-6, 6]])\n",
    "kernel = kernels.get_rbf_kernel(1)\n",
    "kernel = kernels.get_funnel_kernel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(18.800673, dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = proposal.sample(400)\n",
    "stein.ksd_squared_u(sample, target.logpdf, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# uniform dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray([1])\n",
    "scale=np.asarray(2)\n",
    "jax.scipy.stats.uniform.pdf(x, loc=x, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_fun(lambda x: jax.scipy.stats.uniform.pdf(x, scale=scale), (-5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### thingy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = distributions.Gaussian(0, 0.1)\n",
    "proposal = distributions.Gaussian(0, 5)\n",
    "n_particles = 200\n",
    "n_iter = 5\n",
    "n_iter_kernel = 20\n",
    "svgd_lr = 0.05\n",
    "kernel_lr = 0.1\n",
    "sizes = [1]\n",
    "\n",
    "key, subkey, svgd_key = random.split(key, 3)\n",
    "learner = kernel_learning.AdversarialSVGD(subkey, target, proposal, sizes, svgd_lr=svgd_lr, kernel_lr=kernel_lr, svgd_key=svgd_key, n_particles=n_particles)\n",
    "\n",
    "s = kernel_learning.SVGD(\n",
    "    svgd_key, target, proposal,\n",
    "    n_particles=n_particles,\n",
    "    learning_rate=svgd_lr, \n",
    "    get_kernel=lambda par: kernels.get_rbf_kernel(1.),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(s.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(learner.svgd.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slkdfj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is $T \\colon x \\mapsto x + \\varepsilon \\phi^*(x)$ invertible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = distributions.Gaussian(0, 1)\n",
    "target = distributions.Gaussian(0, 15)\n",
    "samples = prop.sample(100)\n",
    "kernel = kernels.get_rbf_kernel(1)\n",
    "\n",
    "eps = 1.\n",
    "# @jit\n",
    "def T(x):\n",
    "    return x + eps * stein.phistar_i(x, samples, target.logpdf, kernel, False)\n",
    "\n",
    "x = np.asarray([1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacfwd(T)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(jacfwd(T)(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test pushforward loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = distributions.Gaussian(0, 1)\n",
    "samples = prop.sample(5)\n",
    "t = lambda x: x*2\n",
    "loglike = metrics.pushforward_loglikelihood(t, vmap(prop.logpdf)(samples), samples)\n",
    "\n",
    "print(samples)\n",
    "print(np.exp(loglike))\n",
    "print(np.exp(vmap(prop.logpdf)(samples))/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiable sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gauss(key, shape, mean, std):\n",
    "    return random.normal(key, shape) * std + mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = distributions.Gaussian(0, 15)\n",
    "learner = kernel_learning.KernelLearner(key, target, [1], kernels.get_rbf_kernel(1), .1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    samples = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New SVGD class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kernel_learning\n",
    "target = distributions.Gaussian(0, 10)\n",
    "proposal = distributions.Gaussian(0, 1)\n",
    "key, subkey = random.split(key)\n",
    "s = kernel_learning.SVGD(subkey, target, proposal, 200)\n",
    "\n",
    "key, subkey = random.split(key)\n",
    "s.flow()\n",
    "\n",
    "plt.plot(s.rundata[\"leader_variance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.rundata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssdf;dfl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirac_kernel(x, y):\n",
    "    return np.where(x==y, 1., 0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirac_kernel(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `vmap` timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, y): return x + y\n",
    "madd = vmap(vmap(add))\n",
    "\n",
    "n=1000\n",
    "x = random.normal(key, (n,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = %timeit -o madd(x,x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_time = %timeit -o add(x,x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what if they're jitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jadd = jit(add)\n",
    "jmadd = jit(madd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = %timeit -o jmadd(x,x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_time = %timeit -o jadd(x,x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernels import defunnelize\n",
    "f = distributions.Funnel(2)\n",
    "s = f.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defunnelize(z):\n",
    "    \"\"\"Inverse of funnelize.\"\"\"\n",
    "    *x, y = np.asarray(z)\n",
    "    print(x)\n",
    "    print(y)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = defunnelize(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmap(defunnelize)(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FunnelizeGaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = distributions.FunnelizedGaussian([0,0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = random.normal(key, (100, 2)) *3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(vmap(fg.pdf)(s) - vmap(fg._pdf)(s)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = fg.sample(1000)\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[8, 8])\n",
    "plot.scatter(s, ax=ax, marker=\".\")\n",
    "ax.set_xlim((-20, 20))\n",
    "ax.set_ylim((-10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdkf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inheritance and `super`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base():\n",
    "    def __init__(self):\n",
    "        self.c = 2\n",
    "    \n",
    "    def method(self, x):\n",
    "        return self.c*x\n",
    "    \n",
    "class Sub(Base):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c = 10\n",
    "        \n",
    "    def method(self, x):\n",
    "        return self.c*super(Sub, self).method(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Sub()\n",
    "test.method(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kernel is not positive definite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mlp = copy.deepcopy(config.config)\n",
    "\n",
    "# conf_mlp[\"svgd\"][\"target_args\"] = [[0, 5], [1, 3]]\n",
    "conf_mlp[\"svgd\"][\"target\"] = \"Gaussian Mixture\"\n",
    "conf_mlp[\"svgd\"][\"target_args\"] = metrics.bent_args\n",
    "\n",
    "conf_mlp[\"svgd\"][\"n_particles\"] = 6000\n",
    "conf_mlp[\"svgd\"][\"n_subsamples\"] = 100\n",
    "conf_mlp[\"svgd\"][\"lam\"] = 1\n",
    "conf_mlp[\"svgd\"][\"encoder_layers\"] = [8, 8, 8, 2]\n",
    "conf_mlp[\"svgd\"][\"decoder_layers\"] = [8, 8, 4, 1]\n",
    "\n",
    "conf_mlp[\"train_kernel\"][\"ksd_steps\"] = 2\n",
    "conf_mlp[\"train_kernel\"][\"svgd_steps\"] = 1\n",
    "conf_mlp[\"train_kernel\"][\"n_iter\"] = 80 #config.config[\"train_kernel\"][\"n_iter\"] // conf_mlp[\"train_kernel\"][\"svgd_steps\"]\n",
    "conf_mlp[\"train_kernel\"][\"optimizer_ksd_args\"] = [0.03]\n",
    "conf_mlp[\"train_kernel\"][\"lamda_reg\"] = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SVGD(**config.get_svgd_args(conf_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, rundata = s.train_kernel(key, **config.get_train_args(conf_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rundata[\"ksd_before_kernel_update_val\"])\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = distributions.GaussianMixture(*conf_mlp[\"svgd\"][\"target_args\"])\n",
    "k = kernels.get_rbf_kernel_logscaled(logh=0)\n",
    "# k = lambda x, y: np.dot(x, y)\n",
    "# k = s.get_kernel_fn(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-6\n",
    "n = 100\n",
    "x = d.sample(n)\n",
    "gram = vmap(vmap(k, (0, None)), (None, 0))(x, x)\n",
    "gram_reg = gram + eps * np.identity(n)\n",
    "print(\"gram PD:\", utils.is_pd(gram))\n",
    "print(\"regularized gram PD:\", utils.is_pd(gram_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, vecs = np.linalg.eig(gram)\n",
    "vals = np.asarray(vals, dtype=np.float32)\n",
    "\n",
    "vals_reg, _ = np.linalg.eig(gram_reg)\n",
    "vals_reg = np.asarray(vals_reg, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(vals_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(key): return random.normal(key)\n",
    "def g(key): return random.normal(key) + 30\n",
    "\n",
    "mix = utils.mixture([f, g], [0.2, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for key in random.split(key, 1000):\n",
    "    x.append(mix(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(x, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = random.split(key)\n",
    "random.randint(subkey, shape=(1,), minval=0, maxval=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting target dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.asarray((1, 2, 1.5, 3, 3.3, 3.8))\n",
    "l = onp.concatenate([-l, [0], l])\n",
    "means = list(zip(l, (l**2)**0.8))\n",
    "variances = [[1,1]]*len(means)\n",
    "weights = [1]*len(means)\n",
    "target = distributions.GaussianMixture(means, variances, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_pdf(target.pdf, (-10, 10), \"contour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.bivariate_hist(target.sample(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test variance of KSD estimators\n",
    "compare U-estimator with linear time estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = distributions.Gaussian(0, 1)\n",
    "source = distributions.Gaussian(0, 1)\n",
    "kernel = kernels.get_rbf_kernel_logscaled(logh=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimate variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 10 # linear time estimator uses L2n samples --> memory L2n, computation Ln, Var(KSD_L) = 1/Ln Var(h(X, Y))\n",
    "      # where n = nr of samples for U-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ksd(n, source, target, mode=\"l\"):\n",
    "    if mode==\"u\":\n",
    "        samples = source.sample(n)\n",
    "        return stein.ksd_squared_u(samples, target.logpdf, kernel)\n",
    "    elif mode==\"l\":\n",
    "        samples = source.sample(2*n).split(2)\n",
    "        return stein.ksd_squared_l(*samples, target.logpdf, kernel, False)\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'u' or 'l'.\")\n",
    "\n",
    "# @partial(jit, static_argnums=range(5))\n",
    "def sample_ksd_variance(n, m, source, target, mode=\"l\"):\n",
    "    return np.var(np.asarray([sample_ksd(n, source, target, mode) for _ in range(m)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "vars_u = []\n",
    "vars_l = []\n",
    "ngrid = 2**onp.arange(5, 10)\n",
    "\n",
    "for n in ngrid:\n",
    "    print(n)\n",
    "    vars_u.append(sample_ksd_variance(n, m, source, target, \"u\"))\n",
    "    vars_l.append(sample_ksd_variance(L*n, m, source, target, \"l\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_u, vars_l = [np.asarray(x) for x in (vars_u, vars_l)] \n",
    "\n",
    "if not np.all(vars_l / vars_u < 1):\n",
    "    print(\"Variance is too high!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ngrid, vars_l / vars_u, \".\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000000\n",
    "samples = source.sample(m).split(2)\n",
    "hvar = stein.h_var(*samples, target.logpdf, kernel)\n",
    "hvar\n",
    "\n",
    "plt.plot(ngrid, ngrid * L * vars_l, label=\"V_L in practice\")\n",
    "plt.hlines(hvar, xmin=0, xmax=ngrid[-1], label=\"V_L in theory\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ngrid, ngrid * vars_u, \".\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# does jit cache intermediate computations, if useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: yes! But: you don't get around memory constraints (e.g. three nested `vmap`s are always gonna need $n^3$ memory, even if output is a scalar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def means(xs):\n",
    "    compute = [np.mean(xs) for _ in range(100)], [np.mean(xs*2)/2 for _ in range(100)]\n",
    "    return np.asarray(compute)\n",
    "jitmeans = jit(means)\n",
    "@jit\n",
    "def single_mean(xs): return np.mean(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "jittimes = []\n",
    "basetimes = []\n",
    "\n",
    "grid = 2**np.arange(3)\n",
    "for n in grid:\n",
    "    key, subkey = random.split(key)\n",
    "    xs = random.normal(subkey, (n,))\n",
    "    \n",
    "    time = %timeit -o means(xs).block_until_ready()\n",
    "    jittime = %timeit -o jitmeans(xs).block_until_ready()\n",
    "    base = %timeit -o single_mean(xs).block_until_ready()\n",
    "\n",
    "    times.append(time.best)\n",
    "    jittimes.append(jittime.best)\n",
    "    basetimes.append(base.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grid, jittimes, \".\", label=\"jitted\")\n",
    "plt.plot(grid, times, \".\", label=\"normal\")\n",
    "plt.plot(grid, basetimes, \".\", label=\"single mean\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slkfj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x):\n",
    "    n = 1000\n",
    "    xs = np.repeat(x, n)\n",
    "    idv = vmap(lambda x: x)\n",
    "    idvv = vmap(idv)\n",
    "    idvvv = vmap(idvv) now id takes argument of shape (n, n, n)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def h(x, y): return np.exp(np.sum((x - y)**2))\n",
    "# def h_thrice(x, y, z): return h(x, y) * h(x, y) * h(y, z)\n",
    "def h_thrice(x, y, z): return x+y+z\n",
    "\n",
    "\n",
    "def test(xs):\n",
    "    \"\"\"In theory, to compute this it would suffice to compute x + y for all x, y in xs.\n",
    "    Store those in an nxn matrix. \"\"\"\n",
    "    hv   = vmap(h_thrice, (0, None, None))\n",
    "    hvv  = vmap(hv,       (None, 0, None))\n",
    "    hvvv = vmap(hvv,      (None, None, 0))\n",
    "    return np.mean(hvv(xs, xs, xs))\n",
    "\n",
    "jittest = jit(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "xs = random.normal(key, (n,))\n",
    "test(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2**11)**3 * 4 / 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2**11)**2 * 4 / 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk.data_structures.tree_bytes(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "jittimes = []\n",
    "\n",
    "num_reps = 50\n",
    "# grid = [3, 5, 10, 20, 50, 100, 200, 300]\n",
    "grid = 2**np.arange(13)\n",
    "for n in grid:\n",
    "    key, subkey = random.split(key)\n",
    "    xs = random.normal(subkey, (n,))\n",
    "    \n",
    "#     time = %timeit -o test(xs).block_until_ready()\n",
    "    jittime = %timeit -o jittest(xs).block_until_ready()\n",
    "    \n",
    "#     times.append(time.best)\n",
    "    jittimes.append(jittime.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grid, jittimes, \".\", label=\"jitted\")\n",
    "plt.plot(grid, times, \".\", label=\"normal\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sldfj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more sampling stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10**2\n",
    "key, subkey = random.split(key)\n",
    "x = random.normal(subkey, (n,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_factor = np.sum(norm.pdf(x))\n",
    "weights = norm.pdf(x) / normalization_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(x**2 * weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When is stuff zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10**6\n",
    "key, subkey = random.split(key)\n",
    "x = random.normal(subkey, (n,))\n",
    "\n",
    "np.any(jax.scipy.stats.norm.pdf(x) == 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-thesis",
   "language": "python",
   "name": "msc-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
