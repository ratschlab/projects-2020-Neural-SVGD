{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `np.sort`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[2, 3, 4],\n",
       "             [1, 2, 3]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[2,3,4],\n",
    "              [3,2,1]])\n",
    "print(x.shape)\n",
    "np.sort(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[2, 2, 1],\n",
       "             [3, 3, 4]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[2, 3, 4],\n",
       "             [1, 2, 3]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# can `jit` take care of this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_vdot = vmap(np.vdot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x, y):\n",
    "    n = 2 * 10**4\n",
    "    xtiled = np.tile(x, (n, 1))\n",
    "    ytiled = np.tile(y, (n, 1))\n",
    "    out = batched_vdot(xtiled, ytiled)\n",
    "    return out[0]\n",
    "\n",
    "jt = jit(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,1,1])\n",
    "y = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.87 s ± 392 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit test(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 µs ± 2.66 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jt(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jup, it can"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kernel computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import single_rbf, ard\n",
    "for x in np.linspace(-10, 10, 30):\n",
    "    x = np.array([x])\n",
    "    for y in np.linspace(-10, 10, 30):\n",
    "        y = np.array([y])\n",
    "        for h in np.linspace(1, 100, 5):\n",
    "#             print(\"x = \", x)\n",
    "#             print(\"y = \", y)\n",
    "#             print()\n",
    "#             print(\"rbf(x, y): \", single_rbf(x, y, h))\n",
    "#             print(\"ard(x, y): \", ard(x, y, h))\n",
    "#             print()\n",
    "#             print(\"-----------\")\n",
    "            assert single_rbf(x, y, h) == ard(x, y, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## misc jax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "x = random.normal(key, (10,))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply matrices\n",
    "size = 3000\n",
    "x = random.normal(key, (size, size), dtype=np.float32)\n",
    "%timeit np.dot(x, x.T).block_until_ready()  # runs on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp  # original CPU-backed NumPy\n",
    "x = onp.random.normal(size=(size, size)).astype(onp.float32)\n",
    "%timeit np.dot(x, x.T).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import device_put\n",
    "\n",
    "x = onp.random.normal(size=(size, size)).astype(onp.float32)\n",
    "x = device_put(x)\n",
    "%timeit np.dot(x, x.T).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `jit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(x, alpha=1.67, lmbda=1.05):\n",
    "    return lmbda * np.where(x > 0, x, alpha * np.exp(x) - alpha)\n",
    "\n",
    "x = random.normal(key, (1000000,))\n",
    "%timeit selu(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selu_jit = jit(selu)\n",
    "%timeit selu_jit(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def sum_logistic(x):\n",
    "    return np.sum(1.0 / (1.0 + np.exp(-x)))\n",
    "\n",
    "x = np.arange(3.)\n",
    "print(sum_logistic(x))\n",
    "print(grad(sum_logistic)(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random.normal(key, (10, 3))\n",
    "batched_sum = vmap(sum_logistic)\n",
    "batched_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x, y):\n",
    "    return np.sum(x**2 + y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y  = [random.normal(key, (10,3)), random.normal(key + 1, (10,3))]\n",
    "print('single argument:', test(x[0], y[0]), '\\n')\n",
    "print('batch output shape:', vmap(test)(x, y).shape)\n",
    "print('batch output:', vmap(test)(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append(np.array([1,2,3]), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(10, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.split(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = x.split(1)[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_v = row.expand_as(x)\n",
    "r_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_dist = torch.sum((r_v - x) ** 2, 1)\n",
    "print(sq_dist.shape)\n",
    "sq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_dist.view(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_pairwise_distances(x, y=None, dist_mat=None):\n",
    "    if y is None:\n",
    "        y = x\n",
    "    if dist_mat is None:\n",
    "        dtype = x.data.type()\n",
    "        dist_mat = Variable(torch.Tensor(x.size()[0], y.size()[0]).type(dtype))\n",
    "\n",
    "    for i, row in enumerate(x.split(1)):\n",
    "        r_v = row.expand_as(y)\n",
    "        sq_dist = torch.sum((r_v - y) ** 2, 1)\n",
    "        dist_mat[i] = sq_dist.view(1, -1)\n",
    "    return dist_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first question\n",
    "does `jit` cache results if it needs them again? that is, does it skip over repeated computations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10**4\n",
    "def h(x):\n",
    "    for i in range(m):\n",
    "        x += i\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    \"\"\"\n",
    "    computation of h is repeated needlessly\n",
    "    \"\"\"\n",
    "    out = 0\n",
    "    for i in range(10):\n",
    "        out += h(x) + i\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    \"\"\"\n",
    "    h(x) is computed only once\n",
    "    \"\"\"\n",
    "    out = 0\n",
    "    hx = h(x)\n",
    "    for i in range(10):\n",
    "        out += hx + i\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert f1(s) == f2(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit f1(s)\n",
    "%timeit f2(s)\n",
    "%timeit jit(f1)(s).block_until_ready()\n",
    "%timeit jit(f2)(s).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next question:\n",
    "does `lax.fori_loop` compile more quickly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import lax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10**4\n",
    "s = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h1(x):\n",
    "    body = lambda i, val: val + i\n",
    "    for i in range(m):\n",
    "        x = body(i, x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h2(x):\n",
    "    body = lambda i, val: val + i\n",
    "    return lax.fori_loop(0, m, body, init_val=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit(h1)(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit(h2)(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yeees, it does!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next question:\n",
    "when we use `lax.fori_loop`, do we get the same speedup for repeated computations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert h(s) == h1(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we use the lax fori loop h1\n",
    "def f1_lax(x):\n",
    "    \"\"\"\n",
    "    computation of h is repeated needlessly\n",
    "    \"\"\"\n",
    "    out = 0\n",
    "#     for i in range(10):\n",
    "#         out += h1(x) + i\n",
    "        \n",
    "    out = lax.fori_loop(0, 10, lambda i, val: val + h1(x) + i, init_val=out)\n",
    "    return out\n",
    "\n",
    "def f2_lax(x):\n",
    "    \"\"\"\n",
    "    h(x) is computed only once\n",
    "    \"\"\"\n",
    "    out = 0\n",
    "    hx = h1(x)\n",
    "#     for i in range(10):\n",
    "#         out += hx + i\n",
    "        \n",
    "    out = lax.fori_loop(0, 10, lambda i, val: val + hx + i, init_val=out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert f1_lax(s) == f1(s)\n",
    "assert f2_lax(s) == f2(s)\n",
    "assert f1(s) == f2(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still compiles fast:\n",
    "jit(f1_lax)(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit f1_lax(s)\n",
    "%timeit f2_lax(s)\n",
    "%timeit jit(f1_lax)(s).block_until_ready()\n",
    "%timeit jit(f2_lax)(s).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we do indeed have a speedup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to plot 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data.\n",
    "X = np.linspace(-5, 5, 50)\n",
    "Y = np.linspace(-5, 5, 50)\n",
    "X, Y = np.meshgrid(X, Y) # both shape (40, 40)\n",
    "\n",
    "Z = X**2 + Y**2\n",
    "\n",
    "# plot\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-thesis",
   "language": "python",
   "name": "msc-thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
